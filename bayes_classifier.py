import json
import os
import pickle

import pandas as pd
from sklearn.feature_extraction import DictVectorizer
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB


def load_json_files(directory):
    data = []
    labels = []
    for filename in os.listdir(directory):
        if filename.endswith(".json"):
            file_path = os.path.join(directory, filename)
            try:
                with open(file_path, "r") as file:
                    file_data = json.load(file)
                    status = file_data.pop("status", None)
                    if status:
                        flattened_data = flatten_json(file_data)
                        data.append(flattened_data)
                        labels.append(status)
            except json.JSONDecodeError:
                print(f"Skipping file {file_path}: not a valid JSON.")
    return data, labels


def flatten_json(data):
    out = {}
    out["file_extension"] = os.path.splitext(data["path"])[1]
    out["code_data_ratio"] = data.get("code_data_ratio", 0)

    # Flatten sections
    sections = data.get("sections", {})
    for section_name, section_info in sections.items():
        for key, value in section_info.items():
            out[f"section_{section_name}_{key}"] = value

    # Flatten capabilities
    capabilities = data.get("capabilities", {})
    for key, value in capabilities.items():
        out[f"capability_{key}"] = value

    return out


def extract_features(data):
    vectorizer = DictVectorizer(sparse=False)
    features = vectorizer.fit_transform(data)
    feature_names = vectorizer.get_feature_names_out()
    return features, feature_names, vectorizer


# def predict_new_file(file_path, vectorizer, clf):
#     try:
#         with open(file_path, 'r') as file:
#             file_data = json.load(file)
#             flattened_data = flatten_json(file_data)
#             features = vectorizer.transform([flattened_data])
#             prediction = clf.predict(features)
#             return prediction[0]
#     except json.JSONDecodeError:
#         print(f"Skipping file {file_path}: not a valid JSON.")
#         return None


def main():
    # Load JSON files
    benign_data, benign_labels = load_json_files("../safe_data")
    malware_data, malware_labels = load_json_files("../malware_data")

    # Combine data and labels
    data = benign_data + malware_data
    labels = benign_labels + malware_labels

    # Print information about the dataset
    print(f"Total dataset size: {len(data)}")
    print(f"Number of benign samples: {len(benign_data)}")
    print(f"Number of malware samples: {len(malware_data)}")

    # Extract features
    features, feature_names, vectorizer = extract_features(data)

    # Print the number of features
    print(f"Number of features: {features.shape[1]}")

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        features, labels, test_size=0.2, random_state=42
    )

    # Print size of the training set
    print(f"Training set size: {len(X_train)}")

    # Print feature names for verification
    print("Feature names:", feature_names)

    # Train Naive Bayes classifier
    clf = MultinomialNB()
    clf.fit(X_train, y_train)

    # Evaluate the classifier
    y_pred = clf.predict(X_test)
    print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
    print(classification_report(y_test, y_pred))

    # Save feature names to a JSON file
    feature_names_dict = {"feature_names": feature_names.tolist()}
    with open("feature_names.json", "w") as json_file:
        json.dump(feature_names_dict, json_file, indent=4)

    # Save the vectorizer and model for later use
    with open("vectorizer.pkl", "wb") as f:
        pickle.dump(vectorizer, f)
    with open("model.pkl", "wb") as f:
        pickle.dump(clf, f)

    # Commented out predicting new files
    # Example of predicting a new file
    # new_file_path = '../new_file.json'
    # prediction = predict_new_file(new_file_path, vectorizer, clf)
    # if prediction is not None:
    #     print(f"The file {new_file_path} is predicted to be: {prediction}")


if __name__ == "__main__":
    main()
