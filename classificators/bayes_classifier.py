import json
import os
import pickle

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction import DictVectorizer
from sklearn.feature_selection import VarianceThreshold
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB


def load_json_files(directory):
    data = []
    labels = []
    for filename in os.listdir(directory):
        if filename.endswith(".json"):
            file_path = os.path.join(directory, filename)
            try:
                with open(file_path, "r") as file:
                    file_data = json.load(file)
                    status = file_data.pop("status", None)
                    if status:
                        flattened_data = flatten_json(file_data)
                        data.append(flattened_data)
                        labels.append(status)
            except json.JSONDecodeError:
                print(f"Skipping file {file_path}: not a valid JSON.")
    return data, labels


def flatten_json(data):
    out = {}
    out["file_extension"] = os.path.splitext(data["path"])[1]
    out["code_data_ratio"] = data.get("code_data_ratio", 0)

    # Flatten sections
    sections = data.get("sections", {})
    for section_name, section_info in sections.items():
        for key, value in section_info.items():
            out[f"section_{section_name}_{key}"] = value

    # Flatten capabilities
    capabilities = data.get("capabilities", {})
    for key, value in capabilities.items():
        out[f"capability_{key}"] = value

    return out


def extract_features(data):
    vectorizer = DictVectorizer(sparse=False)
    features = vectorizer.fit_transform(data)
    feature_names = vectorizer.get_feature_names_out()
    return features, feature_names, vectorizer


def main():
    # Load JSON files
    benign_data, benign_labels = load_json_files("../data/formatted_data/benign")
    malware_data, malware_labels = load_json_files("../data/formatted_data/malware")

    # Combine data and labels
    data = benign_data + malware_data
    labels = benign_labels + malware_labels

    # Print information about the dataset
    print(f"Total dataset size: {len(data)}")
    print(f"Number of benign samples: {len(benign_data)}")
    print(f"Number of malware samples: {len(malware_data)}")

    # Extract features
    features, feature_names, vectorizer = extract_features(data)

    # Print the number of features before selection
    print(f"Number of features before selection: {features.shape[1]}")

    # Apply Variance Threshold
    selector = VarianceThreshold(threshold=(0.8 * (1 - 0.8)))
    features = selector.fit_transform(features)
    selected_feature_names = feature_names[selector.get_support(indices=True)]

    # Print the number of features after selection
    print(f"Number of features after selection: {features.shape[1]}")

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        features, labels, test_size=0.2, random_state=42
    )

    # Print size of the training set
    print(f"Training set size: {len(X_train)}")

    # Train Naive Bayes classifier
    clf_nb = MultinomialNB()
    clf_nb.fit(X_train, y_train)

    # Evaluate Naive Bayes classifier
    y_pred_nb = clf_nb.predict(X_test)
    print("Naive Bayes Classifier:")
    print(f"Accuracy: {accuracy_score(y_test, y_pred_nb)}")
    print(classification_report(y_test, y_pred_nb))

    # Train Random Forest classifier
    clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf_rf.fit(X_train, y_train)

    # Evaluate Random Forest classifier
    y_pred_rf = clf_rf.predict(X_test)
    print("Random Forest Classifier:")
    print(f"Accuracy: {accuracy_score(y_test, y_pred_rf)}")
    print(classification_report(y_test, y_pred_rf))

    # Save selected feature names to a JSON file
    feature_names_dict = {"feature_names": selected_feature_names.tolist()}
    with open("selected_feature_names.json", "w") as json_file:
        json.dump(feature_names_dict, json_file, indent=4)

    # Save the vectorizer, selector, and models for later use
    with open("vectorizer.pkl", "wb") as f:
        pickle.dump(vectorizer, f)
    with open("selector.pkl", "wb") as f:
        pickle.dump(selector, f)
    with open("model_nb.pkl", "wb") as f:
        pickle.dump(clf_nb, f)
    with open("model_rf.pkl", "wb") as f:
        pickle.dump(clf_rf, f)


if __name__ == "__main__":
    main()
