import json
import os

import pandas as pd
from joblib import dump, load
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import cross_val_score, train_test_split


def load_feature_names(feature_names_file):
    with open(feature_names_file, "r") as file:
        feature_names = [line.strip() for line in file.readlines()]
    return feature_names


def load_data(directory, feature_names):
    data = []
    labels = []

    for subdir in ["benign", "malware"]:
        subdir_path = os.path.join(directory, subdir)
        if os.path.exists(subdir_path):
            for filename in os.listdir(subdir_path):
                if filename.endswith(".json"):
                    file_path = os.path.join(subdir_path, filename)
                    with open(file_path, "r") as f:
                        try:
                            file_data = json.load(f)
                            if "label" in file_data:
                                labels.append(
                                    0 if file_data["label"] == "benign" else 1
                                )
                                del file_data["label"]

                                # Merge features with 0 if they are not present
                                for feature in feature_names:
                                    if feature not in file_data:
                                        file_data[feature] = 0

                                data.append(file_data)
                            else:
                                print(
                                    f"Skipping file {file_path}: 'label' key not found."
                                )
                        except json.JSONDecodeError:
                            print(f"Skipping file {file_path}: not a valid JSON.")
                        except Exception as e:
                            print(f"Skipping file {file_path}: {e}")

    return data, labels


def preprocess_data(data):
    df = pd.DataFrame(data)
    df.fillna(0, inplace=True)  # Fill missing values with 0

    # Handle categorical data
    if "file_extension" in df.columns:
        one_hot = pd.get_dummies(df["file_extension"])
        df = df.drop("file_extension", axis=1)
        df = df.join(one_hot)

    return df


def reorder_features(df):
    return df[sorted(df.columns)]


def train_and_evaluate(directory, feature_names_file):
    # Load feature names
    feature_names = load_feature_names(feature_names_file)

    # Load and preprocess data
    data, labels = load_data(directory, feature_names)

    # Debugging statements
    print(f"Loaded {len(data)} files.")
    if len(data) == 0:
        print("No data loaded. Exiting.")
        return

    # Split into features and target
    X = preprocess_data(data)
    y = labels

    # Reorder features alphabetically
    X = reorder_features(X)

    # Further debugging
    print(f"Feature matrix shape: {X.shape}")
    print(f"Labels array length: {len(y)}")

    # Split into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # Initialize and train the Random Forest classifier
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X_train, y_train)

    # Save the trained model
    model_path = os.path.join(directory, "random_forest_model.joblib")
    dump(clf, model_path)
    print(f"Model saved to {model_path}")

    # Make predictions
    y_pred = clf.predict(X_test)
    # Evaluate the classifier
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Classification Report:")
    print(classification_report(y_test, y_pred))

    # Perform cross-validation
    cv_scores = cross_val_score(clf, X, y, cv=5)
    print("Cross-Validation Scores:", cv_scores)
    print("Mean Cross-Validation Score:", cv_scores.mean())

    # Feature importance
    feature_importances = pd.Series(clf.feature_importances_, index=X.columns)
    print("Feature Importances:")
    print(feature_importances.sort_values(ascending=False).head(10))


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Train and evaluate a Random Forest classifier on malware dataset."
    )
    parser.add_argument(
        "directory",
        help="Root directory containing 'benign' and 'malware' subdirectories with JSON files",
    )
    parser.add_argument(
        "feature_names_file",
        help="File containing the list of all possible feature names",
    )

    args = parser.parse_args()

    train_and_evaluate(args.directory, args.feature_names_file)
