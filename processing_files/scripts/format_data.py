import json
import os
import shutil


def load_json_files(directory, problem_directory):
    data = []
    unique_capabilities = set()
    processed_files = 0
    skipped_files_missing_status = 0
    skipped_files_invalid_json = 0

    if not os.path.exists(problem_directory):
        os.makedirs(problem_directory)

    for filename in os.listdir(directory):
        if filename.endswith(".json"):
            file_path = os.path.join(directory, filename)
            try:
                with open(file_path, "r") as file:
                    file_data = json.load(file)
                    if "status" not in file_data:
                        print(f"Skipping file {file_path}: missing 'status' field.")
                        skipped_files_missing_status += 1
                        shutil.move(
                            file_path, os.path.join(problem_directory, filename)
                        )
                        continue
                    flattened_data = flatten_json(file_data)
                    data.append((flattened_data, filename))
                    processed_files += 1

                    # Collect unique capabilities
                    capabilities = file_data.get("capabilities", {})
                    unique_capabilities.update(capabilities.keys())
            except json.JSONDecodeError:
                print(f"Skipping file {file_path}: not a valid JSON.")
                skipped_files_invalid_json += 1
                shutil.move(file_path, os.path.join(problem_directory, filename))

    print(f"Processed {processed_files} files successfully.")
    print(
        f"Skipped {skipped_files_missing_status} files due to missing 'status' field."
    )
    print(f"Skipped {skipped_files_invalid_json} files due to invalid JSON.")

    return data, unique_capabilities


def flatten_json(data):
    out = {}
    out["file_extension"] = os.path.splitext(data["path"])[1]
    out["code_data_ratio"] = data.get("code_data_ratio", 0)

    # Flatten sections
    sections = data.get("sections", {})
    for section_name, section_info in sections.items():
        size = section_info.get("size", 0)
        out[f"section_{section_name}_size"] = size

    # Flatten capabilities
    capabilities = data.get("capabilities", {})
    for key, value in capabilities.items():
        if key in [
            "data_size",
            "code_size",
            "function_count",
            "export_count",
            "import_count",
        ]:
            out[f"capability_{key}"] = value  # Use the actual numerical value
        else:
            out[f"capability_{key}"] = (
                value if isinstance(value, int) else 1
            )  # Binary feature indicating presence

    # Add status as label
    out["label"] = data["status"]

    return out


def format_and_save_individual_files(directory, output_directory, problem_directory):
    data, unique_capabilities = load_json_files(directory, problem_directory)

    if not os.path.exists(output_directory):
        os.makedirs(output_directory)

    for sample, filename in data:
        for capability in unique_capabilities:
            if f"capability_{capability}" not in sample:
                sample[f"capability_{capability}"] = 0

        output_path = os.path.join(output_directory, filename)
        with open(output_path, "w") as outfile:
            json.dump(sample, outfile, indent=4)
        print(f"Saved formatted file: {output_path}")


# Example usage
benign_directory = "../safe_data"
malware_directory = "../malware_data"
benign_output_directory = "formatted_data/benign"
malware_output_directory = "formatted_data/malware"
problem_files_directory = "problem_files"

# Format and save benign files
format_and_save_individual_files(
    benign_directory, benign_output_directory, problem_files_directory
)

# Format and save malware files
format_and_save_individual_files(
    malware_directory, malware_output_directory, problem_files_directory
)
